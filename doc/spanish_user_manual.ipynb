{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Cambia el directorio a la raíz del repositorio si es necesario\n",
    "if os.path.exists(\"spanish_user_manual.ipynb\"):\n",
    "    jupyter_path = os.getcwd()\n",
    "    orca_path = os.path.abspath(os.path.join(jupyter_path, os.pardir))\n",
    "\n",
    "    os.chdir(orca_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [¿Qué es ORCA-Python?](#¿Qué-es-ORCA-Python?)\n",
    "2. [Instalación](#Instalación)\n",
    "    1. [Requisitos para la Instalación](#Requisitos-para-la-Instalación)\n",
    "    2. [Compilación de Algoritmos](#Compilación-de-Algoritmos)\n",
    "    3. [Probando la Instalación](#Probando-la-Instalación)\n",
    "3. [Desinstalación](#Desinstalación)\n",
    "4. [¿Cómo utilizar ORCA-Python?](#¿Cómo-utilizar-ORCA-Python?)\n",
    "    1. [Archivos de Configuración](#Archivos-de-Configuración)\n",
    "        1. [general-conf](#general-conf)\n",
    "        2. [configurations](#configurations)\n",
    "    2. [Parámetros de los Nuevos Algoritmos](#Parámetros-de-los-Nuevos-Algoritmos)\n",
    "    3. [Formato de las Bases de Datos](#Formato-de-las-Bases-de-Datos)\n",
    "    4. [Ejecutando un Experimento](#Ejecutando-un-Experimento)\n",
    "    5. [Formato de los Resultados](#Formato-de-los-Resultados)\n",
    "5. [Utilizando REDSVM y SVOREX](#Utilizando-REDSVM-y-SVOREX)\n",
    "    1. [REDSVM](#REDSVM)\n",
    "    2. [SVOREX](#SVOREX)\n",
    "6. [Referencias](#Referencias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es ORCA-Python?\n",
    "\n",
    "ORCA-Python [1] es un *framework* escrito en Python [2], completamente integrado con los módulos `scikit-learn` [3] y `sacred` [4], cuyo objetivo es el de automatizar la ejecución de experimentos de *machine learning* utilizando ficheros de configuración fáciles de entender.\n",
    "\n",
    "Este *framework* es compatible con cualquier algoritmo que se encuentre implementado en `scikit-learn` o bien creado por el usuario siempre que siga las reglas de compatibilidad con dicha librería [5]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalación\n",
    "ORCA-Python [1] se ha desarrollado y probado en GNU/Linux utilizando Python 2 y Python 3 [2].\n",
    "\n",
    "## Requisitos para la Instalación\n",
    "La correcta ejecución de *framework* requiere de la instalación de las siguientes dependencias de Python:\n",
    "\n",
    "- `numpy` [6] (probado con la versión 1.18.1).\n",
    "- `pandas` [7] (probado con la versión 1.0.1).\n",
    "- `sacred` [4] (probado con la versión 0.8.1).\n",
    "- `scikit-learn` [3] (probado con la versión 0.22.1).\n",
    "- `scipy` [8] (probado con la versión 1.4.1).\n",
    "\n",
    "Para la instalación de todas las dependencias se incluye el archivo `requirements.txt`, que facilitará el proceso utilizando el gestor de paquetes `pip` [9]. \n",
    "\n",
    "Al utilizar el siguiente comando se instalarán todas las dependencias. Si se quiere ejecutar en una consola fuera de este cuaderno Jupyter se debe eliminar la exclamación del principio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilación de Algoritmos\n",
    "Aunque es cierto que ORCA-Python está escrito en Python y no necesita ninguna compilación, algunos algoritmos como REDSVM [10, 11, 12] y SVOREX [12, 13, 14] se encuentran escritos en C++ [15] y C [16], respectivamente. Por ello, antes de empezar a utilizar el *framework*, se debe ejecutar el comando `$ make` en la raíz del repositorio descargado para que se compilen todos los algoritmos que lo necesiten. Al ser un cuarderno de Jupyter a los comandos de consola como `make` se le añade la exclamación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que la compilación de los algoritmos se realiza con el intérprete de Python por defecto en el sistema o entorno virtual. Si en algún momento se ejecuta el *framework* con un intérprete distinto al que se utilizó al compilar los algoritmos, se producirá un error al tratar de ejecutar alguno de ellos.\n",
    "\n",
    "Si se quiere utilizar un intérprete distinto, se debe ejecutar `$ make clean` en la raíz del repositorio para limpiar la compilación anterior y volver a ejecutar `$ make` con el nuevo intérprete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make clean\n",
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando la Instalación\n",
    "Se proporcionan varias bases de datos y un experimento para comprobar que la instalación se ha realizado correctamente. Para realizar esta prueba se debe ejecutar lo siguiente desde la raíz del repositorio del *framework*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config.py with configurations/full_functionality_test.json -l ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que recordar que se debe usar el comando `python` sin el signo de exclamación. En este caso se utiliza así para permitir la ejecución del *framework* desde un cuaderno de Jupyter. Si la ejecución termina sin errores el proceso de instalación habrá sido correcto.\n",
    "\n",
    "Para explicar la información que proporciona el \\textit{framework} sobre el avance del experimento, se analizará la salida generada al entrenar los diferentes modelos con el primer conjunto de datos que carga:\n",
    "\n",
    "- `Running tae dataset` indica que el conjunto de datos \\texttt{tae} ha sido cargado y se va a proceder a ejecutar los diferentes algoritmos sobre sus particiones.\n",
    "- `Running REDSVM ...` indica que se va a empezar a aplicar el algoritmo llamado REDSVM en la configuración sobre las diferentes particiones del conjunto de datos actual.\n",
    "- `Running Partition X` indica la partición sobre la que se está aplicando un determinado algoritmo.\n",
    "- Por último, tras completar toda la experimentación, aparece el mensaje \\texttt{Saving Results{\\ldots}}. Esto indica que se están generando los archivos de resumen con las medias y desviaciones típicas a lo largo de todas las particiones para cada conjunto de datos y algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desinstalación\n",
    "Si la instalación se ha realizado en un entorno virtual, eliminar ORCA-Python [1] del sistema es tan sencillo como eliminar la carpeta donde se clonó el repositorio de GitHub y también la carpeta del propio entorno virtual si no se desea conservar.\n",
    "\n",
    "En el caso de que la instalación de las dependencias se haya realizado sobre la instalación de Python [2] del sistema o se quiera mantener el entorno virtual, para realizar la desinstalación de las mismas se deberá usar, desde la raíz del repositorio del *framework*, el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall --yes -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras ejecutar este comando todas las dependencias instaladas quedarán eliminadas del sistema y solo quedará borrar la carpeta donde se clonó el repositorio de GitHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cómo utilizar ORCA-Python?\n",
    "\n",
    "Este manual hace uso de tres bases de datos (`balance-scale`, `contact-lenses` y `tae`) que se encuentran en la carpeta *datasets*. Estas bases de datos se han particionado utilizando un *30-holdout* (es decir, 30 particiones de tipo holdout), teniendo cada partición una parte de entrenamiento y otra de *test*.\n",
    "\n",
    "## Archivos de Configuración\n",
    "\n",
    "Los experimentos se lanzan y configuran a través de ficheros de configuración en formato JSON. Estos archivos cuentan con dos secciones:\n",
    "\n",
    "- **Configuración general:** Llamada `general-conf` en el archivo de configuración, se encarga de indicar información básica acerca del experimento a realizar: localización de los conjuntos de datos, nombres de los diferentes *datasets* que utilizarán, número de *k-folds* a utilizar para la validación cruzada...\n",
    "- **Configuraciones:** Llamada `configurations` en el archivo de configuración, indica al *framework* aquellos algoritmos que se utilizarán en el experimento. Además para cada uno de ellos es posible indica que parámetros utilizar o ajustar entre dos o más valores. \n",
    "\n",
    "Ambas secciones se encontrarán en el interior de un diccionario que tendrá como claves los nombres de las secciones mencionadas.\n",
    "\n",
    "Para comprender mejor como se estructuran estos ficheros se pondrá como ejemplo el archivo de configuración utilizado en la sección [Probando la Instalación](#Probando-la-Instalación).\n",
    "\n",
    "### `general-conf`\n",
    "\n",
    "Se muestra a continuación la sección `general-conf` del archivo `full_functionality_test.json`:\n",
    "\n",
    "```\n",
    "\"general_conf\": {\n",
    "\n",
    "    \"basedir\": \"ordinal-datasets/ordinal-regression/\",\n",
    "    \"datasets\": [\"tae\", \"balance-scale\", \"contact-lenses\"],\n",
    "    \"hyperparam_cv_folds\": 3,\n",
    "    \"jobs\": 10,\n",
    "    \"input_preprocessing\": \"std\",\n",
    "    \"output_folder\": \"my_runs/\",\n",
    "    \"metrics\": [\"ccr\", \"mae\", \"amae\", \"mze\"],\n",
    "    \"cv_metric\": \"mae\"\n",
    "}\n",
    "```\n",
    "\n",
    "- **`basedir`:** Es la ruta a la carpeta que contiene los conjuntos de datos, solo se permite una única ruta. Admite tanto una ruta relativa como una absoluta.\n",
    "- **`datasets`:** Es el nombre de las bases de datos que se utilizarán en el experimento. El nombre de los conjuntos de datos que se especifiquen aquí deberá corresponderse con una carpeta dentro de `basedir` en el que se encuentren sus diferentes particiones.\n",
    "- **`hyperparam_cv_folds`:** Número de *folds* que se utilizarán en la validación cruzada cuando se optimicen los hiperparámetros.\n",
    "- **`jobs`:** Número de procesos que se lanzarán durante la validación cruzada. Si se utiliza -1 se usarán todos los núcleos del procesador por defecto.\n",
    "- **`input_preprocessing`:** Tipo de preprocesamiento que aplicar a los datos, siendo `std` para estandarización y `norm` para normalización. Si se especifica una cadena vacía (`''`) o se omite la opción, el preprocesado de los datos no se realiza.\n",
    "- **`output_folder`:** Ruta de la carpeta donde almacenar los resultados de los experimentos.\n",
    "- **`metrics`:** Nombre de las métricas de rendimiento que se utilizarán durante el experimento. Se pueden indicar varias como se observa en el ejemplo.\n",
    "- **`cv_metric`:** Es la métrica que utilizará `GridSearchCV` para determinar los mejores parámetros para cada clasificador.\n",
    "\n",
    "Aunque la mayoría de estas variables cuentan con valores por defecto ya contenidos en el archivo `config.py`, las variables `basedir` y `datasets` deben ser especificadas. Se debe tener en cuenta, que no se debe cambiar el nombre de las carpetas proporcionadas al archivo de configuración o el procedimiento fallará.\n",
    "\n",
    "### `configurations`\n",
    "\n",
    "Contiene los diferentes algoritmos que se aplicarán sobre los conjuntos de datos especificados en la sección anterior. Cada algoritmo contendrá los valores que tomarán sus hiperparámetros, ya sea un valor fijo o una colección de valores. De dicha colección de valores se elegirá uno durante la fase de validación cruzada.\n",
    "\n",
    "Si varias configuraciones de algoritmos tienen el mismo nombre solo se utilizará la primera. Se muestra a continuación la sección `configurations` del archivo `full_functionality_test.json`:\n",
    "\n",
    "```\n",
    "\"configurations\": {\n",
    "\n",
    "    \"SVM\": {\n",
    "\n",
    "        \"classifier\": \"sklearn.svm.SVC\",\n",
    "        \"parameters\": {\n",
    "            \"C\": [0.001, 0.1, 1, 10, 100],\n",
    "            \"gamma\": [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "\n",
    "\n",
    "    \"SVMOP\": {\n",
    "\n",
    "        \"classifier\": \"OrdinalDecomposition\",\n",
    "        \"parameters\": {\n",
    "            \"dtype\": \"OrderedPartitions\",\n",
    "            \"decision_method\": \"frank_hall\",\n",
    "            \"base_classifier\": \"sklearn.svm.SVC\",\n",
    "            \"parameters\": {\n",
    "                \"C\": [0.01, 0.1, 1, 10],\n",
    "                \"gamma\": [0.01, 0.1, 1, 10],\n",
    "                \"probability\": [\"True\"]\n",
    "            }\n",
    "\n",
    "        }\n",
    "    },\n",
    "\n",
    "\n",
    "    \"LR\": {\n",
    "\n",
    "        \"classifier\": \"OrdinalDecomposition\",\n",
    "        \"parameters\": {\n",
    "            \"dtype\": [\"OrderedPartitions\", \"OneVsNext\"],\n",
    "            \"decision_method\": \"exponential_loss\",\n",
    "            \"base_classifier\": \"sklearn.linear_model.LogisticRegression\",\n",
    "            \"parameters\": {\n",
    "                \"C\": [0.01, 0.1, 1, 10],\n",
    "                \"penalty\": [\"l1\",\"l2\"]\n",
    "            }\n",
    "\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    \"REDSVM\": {\n",
    "\n",
    "\t\"classifier\": \"REDSVM\",\n",
    "\t\"parameters\": {\n",
    "\t    \"t\": 2,\n",
    "\t    \"c\": [0.1, 1, 10],\n",
    "\t    \"g\": [0.1, 1, 10],\n",
    "\t    \"r\": 0,\n",
    "\t    \"m\": 100,\n",
    "\t    \"e\": 0.001,\n",
    "\t    \"h\": 1\n",
    "\t}\n",
    "\n",
    "    },\n",
    "    \n",
    "    \"SVOREX\": {\n",
    "\n",
    "\t\"classifier\": \"SVOREX\",\n",
    "\t\"parameters\": {\n",
    "\t    \"kernel_type\": 0,\n",
    "\t    \"c\": [0.1, 1, 10],\n",
    "\t    \"k\": [0.1, 1, 10],\n",
    "\t    \"t\": 0.001\n",
    "\t}\n",
    "\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "El nombre de cada configuración será el que quiera el usuario. Se describen a continuación los parámetros que debe tener toda configuración para ser válida:\n",
    "\n",
    "- **`classifier`:** Especifica el clasificador a utilizar. Hay dos formas de especificarlo:\n",
    "    - Ruta relativa al algoritmo de `scikit-learn` [3].\n",
    "    - Nombre de la clase del algoritmo en la carpeta *Classifiers* de la raíz del *framework*.\n",
    "- **`parameters`:** Hiperparámetros a optimizar durante la validación cruzada. No es necesario especificar una lista, se puede especificar un único valor a utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parámetros de los Nuevos Algoritmos\n",
    "\n",
    "Los nuevos algoritmos introducidos han sido REDSVM [10, 11, 12] y SVOREX [12, 13, 14], cada uno con una serie de parámetros que se pueden modificar y que se detallarán a continuación.\n",
    "\n",
    "### Parámetros de REDSVM\n",
    "\n",
    "- **`t`:** Número entero que determina el tipo de *kernel* que se utilizará. Los tipos son los siguientes:\n",
    "    - **`t = 0`:** Tipo lineal.\n",
    "\t- **`t = 1`:** Tipo polinomial.\n",
    "\t- **`t = 2`:** Tipo radial (Por defecto).\n",
    "\t- **`t = 3`:** Tipo sigmoide.\n",
    "\t- **`t = 4`:** Tipo *stump*.\n",
    "\t- **`t = 5`:** Tipo perceptrón.\n",
    "\t- **`t = 6`:** Tipo laplaciano.\n",
    "\t- **`t = 7`:** Tipo exponencial.\n",
    "\t- **`t = 8`:** *Kernel* de tipo preprocesado (los valores del *kernel* se encuentran en los datos de entrenamiento).\n",
    "- **`d`:** Grado del kernel polinomial (Es 3 por defecto).\n",
    "- **`g`:** Valor de gamma en la función de *kernel* (Es 1/Número de características).\n",
    "- **`r`:** Valor del término independiente de la función de *kernel* (Es 0 por defecto).\n",
    "- **`c`:** Valor de coste del error. (Es 1 por defecto).\n",
    "- **`m`:** Tamaño de la memoria caché en *Megabytes*. (Es 100 por defecto).\n",
    "- **`e`:** Tolerancia del criterio de terminación. (Es 0.001 por defecto).\n",
    "- **`h`:** Determina si se utiliza la heurística *Shrinking* [17]. (Es 1 por defecto).\n",
    "\n",
    "### Parámetros de SVOREX\n",
    "\n",
    "- **`kernel_type`:** Número entero que determina el tipo de *kernel* que se utilizará. Los tipos son los siguientes:\n",
    "    - **`kernel_type = 0`:** Tipo gausiano (Por defecto).\n",
    "\t- **`kernel_type = 1`:** Tipo lineal.\n",
    "\t- **`kernel_type = 2`:** Tipo polinomial\n",
    "- **`p`:** Orden del kernel polinomial (Es 2 por defecto).\n",
    "- **`t`:** Tolerancia del criterio de terminación (Es 0.001 por defecto).\n",
    "- **`k`:** Valor de kappa (Es 1 por defecto).\n",
    "- **`c`:** Valor de coste del error (Es 1 por defecto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formato de las Bases de Datos\n",
    "\n",
    "Como se vio en la sección [Archivos de configuración](#Archivos-de-configuración) el usuario habrá especificado una determinada carpeta donde se encuentran los conjuntos de datos, llamada por ejemplo `folder`. De esa forma el conjunto de datos `dataset` se encontrará en la ruta: `folder/dataset/`.\n",
    "\n",
    "En el interior de dicha carpeta se encontrarán los ficheros que contienen la base datos. En caso de no ser una base de datos particionada el nombre de los ficheros será: `train_dataset.csv` en caso de ser el fichero que contiene los datos de entrenamiento y `test_dataset.csv` en caso de ser el fichero que contiene los datos de *test*. En el caso de ser una base de datos particionada, la extensión del `.csv` de los ficheros cambia por el número de la partición.\n",
    "\n",
    "El interior de los ficheros están estructurados como archivos CSV (*Comma Separated Value*), aunque se podría usar cualquier delimitador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"images/data_base_format.png\">\n",
    "  <figcaption>Conjunto de datos compatible con ORCA-Python</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada línea representa un patrón de datos y cada columna representa una variable de dicho patrón, excepto por la última columna, que representa la clase a la que pertenece el patrón. Las variables se pueden representar como valores reales o enteros y las clases como números enteros. No se admiten valores nominales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutando un Experimento\n",
    "\n",
    "Lanzar un experimento es tan simple como ejecutar con el interprete de Python [2] el fichero `config.py` y especificar el archivo de configuración que se desea utilizar. El comando a utilizar sería el siguiente:\n",
    "\n",
    "`$ python config.py with experiment_file.json`\n",
    "\n",
    "Esta forma de ejecución tiene dos problemas:\n",
    "- No se pueden reproducir los resultados puesto que la semilla utilizada es aleatoria.\n",
    "- El paquete `sacred` imprime mucha información por pantalla que realmente no interesa.\n",
    "\n",
    "La solución a estos problemas es simple. Se puede añadir una determinada semilla al comando:\n",
    "\n",
    "`$ python config.py with experiment_file.json seed=12345`\n",
    "\n",
    "Al igual que es posible silenciar `sacred` si al comando anterior le añadimos `-l ERROR`:\n",
    "\n",
    "`$ python config.py with experiment_file.json seed=12345 -l ERROR`\n",
    "\n",
    "Se han incluido dos ficheros de configuración para realizar un experimento utilizando los nuevos algoritmos REDSVM y SVOREX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config.py with configurations/redsvm_test.json seed=12345 -l ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python config.py with configurations/svorex_test.json seed=12345 -l ERROR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formato de los Resultados\n",
    "\n",
    "A lo largo de la ejecución de un experimento y al finalizar el mismo sin ningún error, el *framework* almacena toda la información producida.\n",
    "\n",
    "Se supondrá que se ha configurado la opción `output_folder` con la ruta `my_runs`. En la raíz del repositorio se generará dicha carpeta si no existe y será en su interior donde se almacenen los resultados de los experimentos. \n",
    "\n",
    "Cada experimento genera una carpeta con el nombre `exp-año-mes-día-hora-minuto-segundo`. En su interior se generará lo siguiente:\n",
    "\n",
    "- **Subcarpetas BBDD-Clasificador:** Se generarán tantas subcarpetas como combinaciones de conjunto de datos y clasificadores haya. En el interior de estas carpetas habrá lo siguiente:\n",
    "    - Una carpeta con los mejores modelos obtenidos en la fase de validación. Uno por partición del conjunto de datos.\n",
    "    - Una carpeta con las predicciones realizadas por el mejor modelo de cada partición, tanto las del conjunto de entrenamiento y de *test*.\n",
    "    - Un archivo CSV que contendrá las métricas especificadas en el archivo de configuración y los tiempos computacionales requeridos en cada fase de entrenamiento. Las métricas se calculan de forma independiente para los conjuntos de entrenamiento y *test*, almacenando solo los mejores resultados por partición. También se almacenan los parámetros del clasificador seleccionados como mejores. Cada fila del fichero se corresponde con una partición.\n",
    "    \n",
    "- **Ficheros Resumen:** Al final del experimento se generarán dos ficheros, uno para las métricas obtenidas con los conjuntos de entrenamiento y otro para las de *test*. En este fichero existirá tantas filas como bases de datos y para cada una se calculará la media y desviación típica de cada una de las métricas y tiempos computacionales obtenidos.\n",
    "\n",
    "Para ilustrar esta sección, a continuación se muestran algunas imágenes del formato de los archivos mencionados y de la estructura de carpetas generada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"images/generated_information.png\">\n",
    "  <figcaption>Ficheros y carpetas generados por un experimento</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"images/folder_exp_data_classifier.png\">\n",
    "  <figcaption>Carpeta de un clasificador y conjunto de datos</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"images/predictions_format.png\">\n",
    "  <figcaption>Fragmento de un fichero de predicciones</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"images/file_data_classifier_format.png\">\n",
    "  <figcaption>Fragmento de un fichero de métricas de una base de datos y clasificador</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src=\"images/file_summary_format.png\">\n",
    "  <figcaption>Fragmento de un fichero resumen</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilizando REDSVM y SVOREX\n",
    "\n",
    "Se expone a continuación la forma de utilizar los clasificadores REDSVM [10, 11, 12] y SVOREX [12, 13, 14] añadidos a ORCA-Python tras el desarrollo del presente Trabajo. Como se observará en las siguientes secciones, utilizar estos clasificadores es igual a utilizar cualquier clasificador de `scikit-learn` [3, 5]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REDSVM\n",
    "\n",
    "El método de reducción de regresión ordinal [12] a clasificadores SVM binarios puede ser categorizado como método de umbral o como método de descomposición.\n",
    "\n",
    "A continuación se probará el clasificador REDSVM implementado en ORCA-Python [1] utilizando un *kernel* radial (por defecto), una importancia del error (c) igual a 10 y el valor de gamma (g) igual a 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "\n",
    "import metrics\n",
    "import pandas as pd\n",
    "\n",
    "path.append(\"classifiers\")\n",
    "redsvmModule = __import__(\"REDSVM\")\n",
    "REDSVM = redsvmModule.REDSVM\n",
    "\n",
    "# Carga los datos de entrenamiento\n",
    "taeTrain = pd.read_csv(\n",
    "    \"datasets/tae/train_tae.0\", header=None, engine=\"python\", sep=None\n",
    ")\n",
    "X_train = taeTrain.values[:, 0:(-1)]\n",
    "y_train = taeTrain.values[:, (-1)]\n",
    "\n",
    "# Carga los datos de test\n",
    "taeTest = pd.read_csv(\"datasets/tae/test_tae.0\", header=None, engine=\"python\", sep=None)\n",
    "X_test = taeTest.values[:, 0:(-1)]\n",
    "y_test = taeTest.values[:, (-1)]\n",
    "\n",
    "# Se selecciona los parámetros del modelo REDSVM\n",
    "redsvmModel = REDSVM(c=10, g=0.01)\n",
    "\n",
    "# Se entrena el modelo REDSVM con los datos de entrenamiento\n",
    "redsvmModel = redsvmModel.fit(X_train, y_train)\n",
    "\n",
    "# Se predicen las etiquetas de test\n",
    "redsvmPredictions = redsvmModel.predict(X_test)\n",
    "\n",
    "# Resultados\n",
    "mae = metrics.mae(y_test, redsvmPredictions)\n",
    "ccr = metrics.ccr(y_test, redsvmPredictions)\n",
    "print(\"Resultados obtenidos\")\n",
    "print(\"MAE = {}\".format(mae))\n",
    "print(\"CCR = {}\".format(ccr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ajuste de los parámetros es determinante en la obtención de buenos resultados. A continuación se muestra como realizando una selección de parámetros utilizando un *4-fold* los resultados del clasificador REDSVM sobre la base de datos tae mejoran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Posibles valores a tomar por los parámetros\n",
    "values = np.logspace(-3, 3, 7).tolist()\n",
    "\n",
    "# Se prepara la selección de parámetros\n",
    "redsvmModel = GridSearchCV(\n",
    "    estimator=REDSVM(), param_grid={\"c\": values, \"g\": values}, cv=4, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Se entrena el modelo REDSVM con los datos de entrenamiento\n",
    "redsvmModel = redsvmModel.fit(X_train, y_train)\n",
    "\n",
    "# Se predicen las etiquetas de test\n",
    "redsvmPredictions = redsvmModel.predict(X_test)\n",
    "\n",
    "# Resultados\n",
    "mae = metrics.mae(y_test, redsvmPredictions)\n",
    "ccr = metrics.ccr(y_test, redsvmPredictions)\n",
    "print(\"Resultados obtenidos\")\n",
    "print(\"MAE = {}\".format(mae))\n",
    "print(\"CCR = {}\".format(ccr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVOREX\n",
    "\n",
    "Es una formulación ordinal del paradigma de las máquinas de vectores soporte. Calcula hiperplanos paralelos discriminantes para los datos y selecciona determinados umbrales imponiendo restricciones explicitas.\n",
    "\n",
    "Se probará el algoritmo SVOREX implementado en ORCA-Python con un *kernel* gaussiano (por defecto), una importancia del error (c) igual a 10 y el valor de kappa (k) igual a 0.01. Como base de datos se usará una de las particiones de la base de datos tae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SVOREX classifier without the need of a __init__.py\n",
    "path.append(\"classifiers\")\n",
    "svorexModule = __import__(\"SVOREX\")\n",
    "SVOREX = svorexModule.SVOREX\n",
    "\n",
    "# Se selecciona los parámetros del modelo SVOREX\n",
    "svorexModel = SVOREX(c=10, k=0.01)\n",
    "\n",
    "# Se entrena el modelo SVOREX con los datos de entrenamiento\n",
    "svorexModel = svorexModel.fit(X_train, y_train)\n",
    "\n",
    "# Se predicen las etiquetas de test\n",
    "svorexPredictions = svorexModel.predict(X_test)\n",
    "\n",
    "# Resultados\n",
    "mae = metrics.mae(y_test, svorexPredictions)\n",
    "ccr = metrics.ccr(y_test, svorexPredictions)\n",
    "print(\"Resultados obtenidos\")\n",
    "print(\"MAE = {}\".format(mae))\n",
    "print(\"CCR = {}\".format(ccr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando los valores de los parámetros utilizando un *4-fold* los resultados del clasificador SVOREX sobre la base de datos tae mejoran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se prepara la selección de parámetros\n",
    "svorexModel = GridSearchCV(\n",
    "    estimator=SVOREX(), param_grid={\"c\": values, \"k\": values}, cv=4, n_jobs=-1\n",
    ")\n",
    "\n",
    "# Se entrena el modelo SVOREX con los datos de entrenamiento\n",
    "svorexModel = svorexModel.fit(X_train, y_train)\n",
    "\n",
    "# Se predicen las etiquetas de test\n",
    "svorexPredictions = svorexModel.predict(X_test)\n",
    "\n",
    "# Resultados\n",
    "mae = metrics.mae(y_test, svorexPredictions)\n",
    "ccr = metrics.ccr(y_test, svorexPredictions)\n",
    "print(\"Resultados obtenidos\")\n",
    "print(\"MAE = {}\".format(mae))\n",
    "print(\"CCR = {}\".format(ccr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias\n",
    "\n",
    "1. Iván Bonaque Muñoz, Pedro Antonio Gutiérrez Peña, and Javier Sánchez Monedero. Framework en python para problemas de clasificación ordinal, 2019.\n",
    "1. G. van Rossum. *Python tutorial. Technical Report CS-R9526, Centrumvoor Wiskunde en Informatica (CWI).* 5 1995.\n",
    "1. Sitio oficial de scikit-learn. https://scikit-learn.org/stable/. [Online. Última consulta: 02-12-2019].\n",
    "1. Sitio oficial de sacred. https://sacred.readthedocs.io/en/stable/index.html. [Online. Última consulta: 26-05-2020].\n",
    "1. Developing scikit-learn estimators.https://scikit-learn.org/stable/developers/develop.html. [Online. Última consulta: 25-04-2020].\n",
    "1. Sitio oficial de numpy. https://numpy.org/. [Online. Última consulta: 02-12-2019].\n",
    "1. Sitio oficial de pandas. https://pandas.pydata.org/. [Online. Última consulta: 02-12-2019].\n",
    "1. Sitio oficial de scipy. https://www.scipy.org/. [Online. Última consulta: 02-12-2019].\n",
    "1. Sitio oficial de pip. https://pypi.org/project/pip/. [Online. Última consulta: 24-05-2020].\n",
    "1. Hsuan-Tien Lin and Ling Li. Reduction from cost-sensitive ordinal ranking to weighted binary classification. *Neural Computation*, 24(5):1329–1367, 2012.\n",
    "1. Ling Li and Hsuan-Tien Lin. Ordinal regression by extended binaryclassification. *Annual Conference on Neural Information Processing Systems,* 19:865–872, 01 2006\n",
    "1. P. A. Gutiérrez, M. Pérez-Ortiz, J. Sánchez-Monedero, F. Fernández-Navarro, and C. Hervás-Martínez. Ordinal regression methods: Surveyand experimental study. *IEEE  Transactions on Knowledge and DataEngineering,* 28(1):127–146, 2016\n",
    "1. W. Chu and S. S. Keerthi. Support vector ordinal regression and its solution. 2004\n",
    "1. Wei Chu and S. Sathiya Keerthi. Support vector ordinal regression. Neural Computation, 19(3):792–815, 2007\n",
    "1. Bjarne Stroustrup. *The C++ Programming Language.* Addison-WesleyPub Co; Tercera edición, 2 2000.\n",
    "1. Brian Kernighan and Dennis Ritchie. *The C Programming Language.* Prentice Hall; Primera edición, 1978.\n",
    "1.  Chih-Chung Chang and Chih-Jen Lin.  LIBSVM: A library for supportvector machines.ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27, 2011.  Software available at http://www.csie.ntu.edu.tw/~cjlin/libsvm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
